{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b685c1-fe44-4f01-b9e3-5808cf10752f",
   "metadata": {},
   "source": [
    "# Chat With Your Data\n",
    "\n",
    "## Persist Data to Vector Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed94b7-d5da-4c5b-a812-25ecbb1601a6",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603889ff-e355-4c9e-929a-45e8150aa0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ae117-0aa2-4c09-b5bd-7ce1e106ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd511c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca531938",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1839e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c527ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fcee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fcee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1dd5a-612c-4225-90c3-389bc2984aaa",
   "metadata": {},
   "source": [
    "## Load OpenAI API Key to use OpenAI's embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7230fb9-edec-4022-8fa2-0108e6587f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "383ee64d-c0b7-4d16-ae88-86fd60411cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58a3a5-e86d-4486-bc11-82f5afd116d9",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a7b7ad-9366-4611-9d66-157652365f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('big-book-of-data-engineering.pdf')\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682ce53-9173-4bbb-9f9c-a8c497ece3d2",
   "metadata": {},
   "source": [
    "## Chunk documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920ee1b5-8551-4bdd-957e-b33caf142ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Load the document, split it into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f38df-c4be-45b9-8cd5-5bd63b9b787a",
   "metadata": {},
   "source": [
    "# Generate embeddings and store in vector database\n",
    "## FAISS vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51379225-5562-4a65-bfe9-adbec6914a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\")\n",
    "# Load it into the vector store and embed\n",
    "vectordb = FAISS.from_documents(documents, embeddings )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75dd936d-9a7d-4a31-a30c-9cb6a7d0f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(vectordb.index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "000353fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'big-book-of-data-engineering.pdf', 'page': 1}, page_content='Challenges of data engineering in the AI era\\nAs previously mentioned, data engineering is key to ensuring reliable data for \\nAI initiatives. Data engineers who build and maintain ETL pipelines and the \\ndata infrastructure that underpins analytics and AI workloads face specific \\nchallenges in this fast-moving landscape. \\n ■ Handling real-time data: From mobile applications to sensor data on \\nfactory floors, more and more data is created and streamed in real \\ntime and requires low-latency processing so it can be used in real-time \\ndecision-making.\\n ■ Scaling data pipelines reliably:  With data coming in large quantities \\nand often in real time, scaling the compute infrastructure that runs \\ndata pipelines is challenging, especially when trying to keep costs low \\nand performance high. Running data pipelines reliably, monitoring data \\npipelines and troubleshooting when failures occur are some of the most \\nimportant responsibilities of data engineers.\\n ■ Data quality: “Garbage in, garbage out.” High data quality is essential to \\ntraining high-quality models and gaining actionable insights from data. \\nEnsuring data quality is a key challenge for data engineers.\\n ■ Governance and security: Data governance is becoming a key challenge \\nfor organizations who find their data spread across multiple systems  \\nwith increasingly larger numbers of internal teams looking to access and \\nutilize it for different purposes. Securing and governing data is also an \\nimportant regulatory concern many organizations face, especially in highly \\nregulated industries.\\nThese challenges stress the importance of choosing the right data platform for \\nnavigating new waters in the age of AI. But a data platform in this new age can \\nalso go beyond addressing just the challenges of building AI solutions. The right \\nplatform can improve the experience and productivity of data practitioners, \\nincluding data engineers, by infusing intelligence and using AI to assist with \\ndaily engineering tasks.\\nIn other words, the new data platform is a data intelligence platform.\\n5\\nEBOOK: THE BIG BOOK OF DATA ENGINEERING — 3RD EDITION')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956e6caf-9748-4071-8fc8-069d17fa7d29",
   "metadata": {},
   "source": [
    "## Persist Data in your Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ca8889-f3f2-4d76-a167-df0b6c951e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.save_local(\"faiss2b_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4c9d0-dc56-4c47-ae74-92868ba6a7c4",
   "metadata": {},
   "source": [
    "## Load Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0347129a-410a-485d-8ce7-21787841a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db = FAISS.load_local(\"faiss2b_index\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067407f2",
   "metadata": {},
   "source": [
    "## Prompt a model with no knowledge of big-book-of-data-engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6782a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#initialize the LLM we'll use - OpenAI GPT 3.5 Turbo\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9256f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(docs,type:int=1):\n",
    "    import textwrap\n",
    "    match type:\n",
    "        case 1:\n",
    "            for doc in docs:\n",
    "                print('The medatadata is: {}'.format(doc.metadata))\n",
    "                for t in textwrap.wrap(doc.page_content,width=100):\n",
    "                    print(t)\n",
    "        case 2:\n",
    "            #print('The medatadata is: {}'.format(docs.response_metadata))\n",
    "            for t in textwrap.wrap(docs.content,width=100):\n",
    "                print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "808b9a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data engineering is a field within data science that involves the design, creation, and maintenance\n",
      "of systems for collecting, storing, and analyzing data. Data engineers are responsible for\n",
      "developing the architecture and infrastructure necessary to support large-scale data processing and\n",
      "analytics tasks. This includes building data pipelines, data warehouses, and databases, as well as\n",
      "implementing data processing algorithms and workflows. Data engineering is crucial for organizations\n",
      "looking to make data-driven decisions and derive valuable insights from their data.\n"
     ]
    }
   ],
   "source": [
    "#prompt the model with no additional knowledge of the big book of data engineering \n",
    "docs = llm.invoke(\"What is data engineering?\")\n",
    "print_output(docs,2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb4762",
   "metadata": {},
   "source": [
    "## Load database from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ca96ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "db = FAISS.load_local(\"../02_02_assignment/faiss2b_index\", \n",
    "                      OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\"), \n",
    "                      allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23484369",
   "metadata": {},
   "source": [
    "## Configure retriever\n",
    "### Use the similarity search capabilities of a vector store to facilitate retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5475e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9cb68e",
   "metadata": {},
   "source": [
    "## Preserve Conversation History "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78ffc766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "system_prompt = \"\"\"Given the chat history and a recent user question \\\n",
    "generate a new standalone question \\\n",
    "that can be understood without the chat history. Do NOT answer the question, \\\n",
    "just reformulate it if needed or otherwise return it as is.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever_with_history = create_history_aware_retriever(\n",
    "    llm, retriever, prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe532b2",
   "metadata": {},
   "source": [
    "## Perform question answering with chat history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7762f1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "qa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\n",
    "Use the following pieces of retrieved context to answer the question. \\\n",
    "If you don't know the answer, just say that you don't know. \\\n",
    "Use three sentences maximum and keep the answer concise.\\\n",
    "\n",
    "{context}\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", qa_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever_with_history, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a904afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data engineering is the practice of processing raw data from a source to store and organize it for various uses such as data analytics, business intelligence, or machine learning model training. It involves preparing data to extract value from it effectively. Data engineering consists of three main parts: ingest, transform, and orchestrate, which are essential for success in data and AI initiatives.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "question = \"What is data engineering?\"\n",
    "\n",
    "ai_msg_1 = rag_chain.invoke({\"input\": question, \"chat_history\": chat_history})\n",
    "\n",
    "chat_history.extend([HumanMessage(content=question), ai_msg_1[\"answer\"]])\n",
    "\n",
    "print(ai_msg_1[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6c9659c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best practices in data engineering include building reliable data pipelines that can efficiently ingest and stream large amounts of data while ensuring high data quality. Data transformation is crucial for filtering, standardizing, cleaning, and aggregating data for usable storage. Orchestration involves scheduling, monitoring, and controlling the data pipeline to handle failures effectively.\n"
     ]
    }
   ],
   "source": [
    "second_question = \"What are its best practices\"\n",
    "\n",
    "ai_msg_2 = rag_chain.invoke({\"input\": second_question, \"chat_history\": chat_history})\n",
    "print(ai_msg_2[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cfdb4b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main challenges of data engineering in the AI era include handling real-time data for low-latency processing, scaling data pipelines reliably while keeping costs low, ensuring high data quality for training quality models, and addressing data governance and security concerns. Data engineers face responsibilities such as running data pipelines reliably, monitoring them, troubleshooting failures, and securing and governing data across multiple systems. Choosing the right data platform is crucial to navigate these challenges successfully in the age of AI.\n"
     ]
    }
   ],
   "source": [
    "third_question = \"What are its main challenges?\"\n",
    "ai_msg_3 = rag_chain.invoke({\"input\": third_question, \"chat_history\": chat_history})\n",
    "print(ai_msg_3[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e7deb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, data governance is crucial as organizations face challenges with data spread across multiple systems and increasing numbers of internal teams accessing it. Securing and governing data is also a regulatory concern, especially in highly regulated industries, emphasizing the importance of data governance to ensure data quality, security, and compliance.\n"
     ]
    }
   ],
   "source": [
    "fourth_question = \"Do you think its data governance is important?\"\n",
    "ai_msg_4 = rag_chain.invoke({\"input\": fourth_question, \"chat_history\": chat_history})\n",
    "print(ai_msg_4[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78f6cc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data governance can be implemented by defining data policies, standards, and procedures, establishing roles and responsibilities for data management, ensuring data quality and security, and monitoring compliance with regulations. Organizations can use data governance tools and technologies to enforce policies, manage metadata, and track data lineage. It is crucial to involve stakeholders across different teams in the organization to ensure successful data governance implementation.\n"
     ]
    }
   ],
   "source": [
    "fifth_question = \"How do you implement data governance?\"\n",
    "ai_msg_5 = rag_chain.invoke({\"input\": fifth_question, \"chat_history\": chat_history})\n",
    "print(ai_msg_5[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
