{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b685c1-fe44-4f01-b9e3-5808cf10752f",
   "metadata": {},
   "source": [
    "# Chat With Your Data\n",
    "\n",
    "## Persist Data to Vector Stores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed94b7-d5da-4c5b-a812-25ecbb1601a6",
   "metadata": {},
   "source": [
    "# Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "603889ff-e355-4c9e-929a-45e8150aa0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ae117-0aa2-4c09-b5bd-7ce1e106ada2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd511c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca531938",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1839e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c527ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fcee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fcee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a1dd5a-612c-4225-90c3-389bc2984aaa",
   "metadata": {},
   "source": [
    "## Load OpenAI API Key to use OpenAI's embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7230fb9-edec-4022-8fa2-0108e6587f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "383ee64d-c0b7-4d16-ae88-86fd60411cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58a3a5-e86d-4486-bc11-82f5afd116d9",
   "metadata": {},
   "source": [
    "## Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0a7b7ad-9366-4611-9d66-157652365f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader('big-book-of-data-engineering.pdf')\n",
    "pages = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8682ce53-9173-4bbb-9f9c-a8c497ece3d2",
   "metadata": {},
   "source": [
    "## Chunk documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "920ee1b5-8551-4bdd-957e-b33caf142ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Load the document, split it into chunks\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "documents = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102f38df-c4be-45b9-8cd5-5bd63b9b787a",
   "metadata": {},
   "source": [
    "# Generate embeddings and store in vector database\n",
    "## FAISS vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51379225-5562-4a65-bfe9-adbec6914a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\")\n",
    "# Load it into the vector store and embed\n",
    "vectordb = FAISS.from_documents(documents, embeddings )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75dd936d-9a7d-4a31-a30c-9cb6a7d0f7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(vectordb.index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "000353fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'big-book-of-data-engineering.pdf', 'page': 1}, page_content='Challenges of data engineering in the AI era\\nAs previously mentioned, data engineering is key to ensuring reliable data for \\nAI initiatives. Data engineers who build and maintain ETL pipelines and the \\ndata infrastructure that underpins analytics and AI workloads face specific \\nchallenges in this fast-moving landscape. \\n ■ Handling real-time data: From mobile applications to sensor data on \\nfactory floors, more and more data is created and streamed in real \\ntime and requires low-latency processing so it can be used in real-time \\ndecision-making.\\n ■ Scaling data pipelines reliably:  With data coming in large quantities \\nand often in real time, scaling the compute infrastructure that runs \\ndata pipelines is challenging, especially when trying to keep costs low \\nand performance high. Running data pipelines reliably, monitoring data \\npipelines and troubleshooting when failures occur are some of the most \\nimportant responsibilities of data engineers.\\n ■ Data quality: “Garbage in, garbage out.” High data quality is essential to \\ntraining high-quality models and gaining actionable insights from data. \\nEnsuring data quality is a key challenge for data engineers.\\n ■ Governance and security: Data governance is becoming a key challenge \\nfor organizations who find their data spread across multiple systems  \\nwith increasingly larger numbers of internal teams looking to access and \\nutilize it for different purposes. Securing and governing data is also an \\nimportant regulatory concern many organizations face, especially in highly \\nregulated industries.\\nThese challenges stress the importance of choosing the right data platform for \\nnavigating new waters in the age of AI. But a data platform in this new age can \\nalso go beyond addressing just the challenges of building AI solutions. The right \\nplatform can improve the experience and productivity of data practitioners, \\nincluding data engineers, by infusing intelligence and using AI to assist with \\ndaily engineering tasks.\\nIn other words, the new data platform is a data intelligence platform.\\n5\\nEBOOK: THE BIG BOOK OF DATA ENGINEERING — 3RD EDITION')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956e6caf-9748-4071-8fc8-069d17fa7d29",
   "metadata": {},
   "source": [
    "## Persist Data in your Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ca8889-f3f2-4d76-a167-df0b6c951e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.save_local(\"faiss2b_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de4c9d0-dc56-4c47-ae74-92868ba6a7c4",
   "metadata": {},
   "source": [
    "## Load Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0347129a-410a-485d-8ce7-21787841a5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_db = FAISS.load_local(\"faiss2b_index\", embeddings, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067407f2",
   "metadata": {},
   "source": [
    "## Prompt a model with no knowledge of big-book-of-data-engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6782a570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "#initialize the LLM we'll use - OpenAI GPT 3.5 Turbo\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9256f3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_output(docs,type:int=1):\n",
    "    import textwrap\n",
    "    match type:\n",
    "        case 1:\n",
    "            for doc in docs:\n",
    "                print('The medatadata is: {}'.format(doc.metadata))\n",
    "                for t in textwrap.wrap(doc.page_content,width=100):\n",
    "                    print(t)\n",
    "        case 2:\n",
    "            #print('The medatadata is: {}'.format(docs.response_metadata))\n",
    "            for t in textwrap.wrap(docs.content,width=100):\n",
    "                print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "808b9a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data engineering is a field within data science that involves the design, creation, and maintenance\n",
      "of systems for collecting, storing, and analyzing data. Data engineers are responsible for\n",
      "developing the architecture and infrastructure necessary to support large-scale data processing and\n",
      "analytics tasks. This includes building data pipelines, data warehouses, and databases, as well as\n",
      "implementing data processing algorithms and workflows. Data engineering is crucial for organizations\n",
      "looking to make data-driven decisions and derive valuable insights from their data.\n"
     ]
    }
   ],
   "source": [
    "#prompt the model with no additional knowledge of the big book of data engineering \n",
    "docs = llm.invoke(\"What is data engineering?\")\n",
    "print_output(docs,2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deb4762",
   "metadata": {},
   "source": [
    "## Load database from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ca96ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "\n",
    "db = FAISS.load_local(\"../02_02_assignment/faiss2b_index\", \n",
    "                      OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY, model=\"text-embedding-3-small\"), \n",
    "                      allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23484369",
   "metadata": {},
   "source": [
    "## Configure retriever\n",
    "### Use the similarity search capabilities of a vector store to facilitate retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5475e348",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f028fa51",
   "metadata": {},
   "source": [
    "## Implement a chain\n",
    "### Chain together multiple calls in a logical sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "528b870d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/langsmith/client.py:261: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5453525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff581d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "#combine multiple steps in a single chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser() #convert the chat message to a string\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d99489",
   "metadata": {},
   "source": [
    "## Send LLM's response to the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bca73625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data engineering is the practice of processing raw data from a source for downstream use in analytics, business intelligence, or machine learning. It involves three main parts: data ingestion, transformation, and orchestration. Challenges in data engineering include handling real-time data, scaling data pipelines, ensuring data quality, and addressing governance and security concerns."
     ]
    }
   ],
   "source": [
    "for chunk in rag_chain.stream(\"What is data engineering?\"):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
